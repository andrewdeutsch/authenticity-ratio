# OpenAI ChatClient Setup Guide

This guide walks you through setting up and testing the OpenAI ChatClient integration for LLM-powered summarization in the AR Tool.

## Overview

The AR Tool uses OpenAI's API for:
- **Abstractive text summarization** in report generation
- **LLM-enhanced descriptions** for content items
- **Intelligent fallbacks** when extractive methods produce poor results

## Prerequisites

1. Python 3.8+ installed
2. OpenAI API account with valid API key
3. AR Tool repository cloned

## Setup Steps

### 1. Install Dependencies

Install the required Python packages:

```bash
# Install all dependencies including OpenAI
pip install -r requirements.txt

# Or install just OpenAI
pip install openai>=1.0.0
```

### 2. Get OpenAI API Key

1. Go to [OpenAI Platform](https://platform.openai.com/api-keys)
2. Sign in or create an account
3. Navigate to "API Keys" section
4. Click "Create new secret key"
5. Copy the key (starts with `sk-`)
6. **Important**: Store it securely - you won't be able to see it again

### 3. Configure Environment Variables

**Option A: Using .env file (Recommended for development)**

```bash
# Copy the example file
cp .env.example .env

# Edit .env and add your key
echo "OPENAI_API_KEY=sk-your-actual-key-here" >> .env
```

**Option B: Export environment variable (Temporary)**

```bash
export OPENAI_API_KEY=sk-your-actual-key-here
```

**Option C: Add to shell profile (Permanent)**

Add to `~/.bashrc` or `~/.zshrc`:

```bash
export OPENAI_API_KEY=sk-your-actual-key-here
```

Then reload: `source ~/.bashrc`

### 4. Verify Installation

Run the standalone test script:

```bash
python scripts/test_llm_standalone.py
```

Expected output:
```
ðŸ§ª OpenAI ChatClient Standalone Test Suite
======================================================================
âœ… PASS       provenance
âœ… PASS       openai_pkg
âœ… PASS       api_key
âœ… PASS       chat_client
âœ… PASS       summarization
======================================================================
âœ… All tests passed! ChatClient is ready to use.
```

## Usage Examples

### Basic ChatClient Usage

```python
from scoring.llm_client import ChatClient

# Initialize client (uses OPENAI_API_KEY from environment)
client = ChatClient()

# Chat completion
response = client.chat(
    messages=[{"role": "user", "content": "Summarize this text..."}],
    model="gpt-3.5-turbo",
    max_tokens=150
)
print(response['content'])

# Convenience method for summarization
summary = client.summarize("Long text here...", max_words=50)
print(summary)
```

### Using Provenance Helper

```python
from reporting.markdown_generator import add_llm_provenance

text = "This is an LLM-generated summary."
labeled = add_llm_provenance(text, "gpt-3.5-turbo")
# Output: "This is an LLM-generated summary. (Generated by gpt-3.5-turbo)"
```

### In Report Generation

The ChatClient is automatically used by report generators when:
- `report_data['use_llm_for_descriptions']` is True
- `report_data['use_llm_for_examples']` is True
- `OPENAI_API_KEY` is configured

Example:

```python
from reporting.markdown_generator import MarkdownReportGenerator

generator = MarkdownReportGenerator()

report_data = {
    'brand_id': 'nike',
    'run_id': 'test-001',
    'use_llm_for_descriptions': True,  # Enable LLM summaries
    'llm_model': 'gpt-3.5-turbo',
    'items': [...],
    # ... other report data
}

generator.generate_report(report_data, 'output/report.md')
```

## Testing

### Test Scripts

1. **Standalone Test** (minimal dependencies):
   ```bash
   python scripts/test_llm_standalone.py
   ```

2. **Full Integration Test** (requires all dependencies):
   ```bash
   python scripts/test_llm_client.py
   ```

3. **With Custom Text**:
   ```bash
   python scripts/test_llm_client.py --text "Your custom text to summarize..."
   ```

### Unit Tests

Run the test suite:

```bash
pytest tests/test_chat_client.py -v
```

## Configuration

### Model Selection

Default model is `gpt-3.5-turbo`. You can specify different models:

```python
client = ChatClient(default_model='gpt-4')

# Or per-request
response = client.chat(messages=[...], model='gpt-4')
```

### Rate Limits

The default rate limit is 60 requests per minute. Configure in `config/settings.py`:

```python
SETTINGS = {
    'openai_rate_limit': 60,  # requests per minute
    # ...
}
```

### Cost Considerations

- **gpt-3.5-turbo**: ~$0.0015 per 1K tokens (input) + $0.002 per 1K tokens (output)
- **gpt-4**: ~$0.03 per 1K tokens (input) + $0.06 per 1K tokens (output)

Monitor usage at: https://platform.openai.com/usage

## Troubleshooting

### Error: "No module named 'openai'"

**Solution**: Install the package
```bash
pip install openai>=1.0.0
```

### Error: "OpenAI API key not configured"

**Solution**: Set the environment variable
```bash
export OPENAI_API_KEY=sk-your-key-here
```

Verify it's set:
```bash
echo $OPENAI_API_KEY
```

### Error: "AuthenticationError: Invalid API key"

**Solution**: Check your key is correct
- Starts with `sk-`
- No extra spaces or quotes
- Not expired or revoked

### Error: "RateLimitError"

**Solution**: You've hit API rate limits
- Wait a few minutes
- Reduce request frequency
- Upgrade your OpenAI plan

### ImportError in report generators

If you get import errors when running reports:

1. Check all dependencies are installed:
   ```bash
   pip install -r requirements.txt
   ```

2. Check Python path includes project root:
   ```python
   import sys
   sys.path.insert(0, '/path/to/authenticity-ratio')
   ```

## Fallback Behavior

The system gracefully falls back to extractive summarization when:
- OpenAI package not installed
- API key not configured
- API request fails
- Rate limits exceeded

This ensures reports can still be generated without LLM support.

## Next Steps

After verifying the setup:

1. **Run the full pipeline** with LLM enabled:
   ```bash
   python scripts/run_pipeline.py --brand nike --use-llm
   ```

2. **Generate a test report** with LLM summaries
3. **Review costs** in OpenAI dashboard
4. **Tune parameters** (max_words, temperature) for your use case

## Additional Resources

- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference)
- [OpenAI Python Library](https://github.com/openai/openai-python)
- [Rate Limits Guide](https://platform.openai.com/docs/guides/rate-limits)
- [Best Practices](https://platform.openai.com/docs/guides/production-best-practices)

## Support

For issues specific to AR Tool integration:
- Check `docs/RECENT_ISSUES.md`
- Review test output from `test_llm_standalone.py`
- Verify configuration in `config/settings.py`

For OpenAI API issues:
- Visit [OpenAI Help Center](https://help.openai.com/)
- Check [API Status](https://status.openai.com/)
